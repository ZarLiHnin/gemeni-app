import { GoogleGenerativeAI } from "@google/generative-ai";
import { NextResponse } from "next/server";

type ChatMessage = {
  role: "user" | "assistant";
  content: string;
};

export async function POST(req: Request) {
  try {
    const {
      prompt,
      history,
      systemPrompt,
    }: {
      prompt: string;
      history: ChatMessage[];
      systemPrompt: string;
    } = await req.json();

    const apiKey = process.env.GEMINI_API_KEY;
    if (!apiKey) throw new Error("GEMINI_API_KEY „ÅåË®≠ÂÆö„Åï„Çå„Å¶„ÅÑ„Åæ„Åõ„Çì");

    const genAI = new GoogleGenerativeAI(apiKey);
    const model = genAI.getGenerativeModel({ model: "gemini-1.5-pro" });

    // üëá ÊúÄÂàù„Å´ systemPrompt „Çí user „É°„ÉÉ„Çª„Éº„Ç∏„Å®„Åó„Å¶Â±•Ê≠¥„Å´ËøΩÂä†
    const historyWithSystem: ChatMessage[] = [
      {
        role: "user",
        content: systemPrompt?.trim() || "„ÅÇ„Å™„Åü„ÅØÂÑ™ÁßÄ„Å™„Ç¢„Ç∑„Çπ„Çø„É≥„Éà„Åß„Åô„ÄÇ",
      },
      ...history,
    ];

    // GeminiÁî®„Å´Â±•Ê≠¥„ÇíÊï¥ÂΩ¢
    const formattedHistory = historyWithSystem.map((msg) => ({
      role: msg.role === "user" ? "user" : "model",
      parts: [{ text: msg.content }],
    }));

    const chatSession = model.startChat({
      history: formattedHistory,
    });

    const result = await chatSession.sendMessageStream(prompt);

    const stream = new ReadableStream({
      async start(controller) {
        const encoder = new TextEncoder();
        for await (const chunk of result.stream) {
          const text = chunk.text();
          controller.enqueue(encoder.encode(text));
        }
        controller.close();
      },
    });

    return new NextResponse(stream, {
      headers: {
        "Content-Type": "text/plain; charset=utf-8",
        "Cache-Control": "no-cache",
      },
    });
  } catch (error) {
    console.error("API Error:", error);
    return NextResponse.json({ error: "ÂÜÖÈÉ®„Çµ„Éº„Éê„Éº„Ç®„É©„Éº" }, { status: 500 });
  }
}
